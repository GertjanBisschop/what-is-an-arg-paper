\documentclass{article}
\usepackage[round]{natbib}
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{geometry}%
\usepackage{color}
\usepackage{graphicx}
\usepackage{authblk}
\usepackage{nameref}
\usepackage[right]{lineno}
\usepackage{subcaption}
\usepackage{tikz}
\usetikzlibrary{calc,positioning}

\begin{document}

\linenumbers
\title{What is an Ancestral Recombination Graph?}
% First authors
\author{Author McAuthorface}
% Corresponding

\maketitle

% JK: this is a rough first pass for a slightly different paper. Needs
% substantial revision.
\begin{abstract}
It has recently become possible to infer genetic ancestry in the presence of
recombination at scale for the first time, enabling many
downstream applications in population and statistical genetics.
Such recombinant genetic ancestry is usually
referred to as an Ancestral Recombination Graph, or ARG.
% Note: slight repetition here with first sentence.
There are now multiple methods that can infer ARGs at a practical scale
and it is therefore vital that these methods can be systematically evaluated
and compared to determine their strengths and weaknesses.
Unfortunately, however, there is substantial confusion over
terminology and little agreement on shared standards for data interchange,
significantly hampering progress in this important area.
This confusion and lack of agreement on basic issues such as what does and
does not constitute an ARG is partly attributable to the historical
development of the term.
Originally rigorously defined as
a stochastic process (the coalescent with recombination) together with its
representation, an ARG is now understood to refer to any
concrete realisation of a recombinant genetic ancestry.
We show that the standard description of an ARG
in terms of common ancestor and recombination events
(inherited from the original stochastic process definition) is
ambiguous, fundamentally limited and an unsuitable basis for data interchange.
We provide a simple alternative definition of an ARG in which a node
corresponds to one of an individual's monoploid genomes, an edge
% jk-note: this is clumsy
defines a genetic ancestry relationship between two nodes,
and annotations on those edges define the precise patterns of
ancestry in intervals along the genome.
We use this framework to define some classifications and metrics of ARG nodes,
and discuss the properties of some recently developed inference methods.
% jk-note: this ends a bit flat - we should say other stuff like we clarify
% how the ARG relates the pedigree, etc, etc. Let's go through again when
% we have a reasonable draft.
\end{abstract}

\textbf{Keywords:} Ancestral Recombination Graphs

\section*{Introduction}
Inferring the genetic relationships between sampled genomes in the form of an
evolutionary tree is a necessary prerequisite for many analyses of species \citep{rannala2003genetics}, non (or
rarely) recombining sections of DNA \citep{cann1987mitochondrial,underhill2001annalsofhumangenetics} and viruses \citep{grenfell2004science}.
A genealogical tree captures what is known and
knowable about the genetic ancestry of the sample in an elegant and concise
way, by postulating a set of nodes that are ancestors common to the samples,
and the ancestral relationships between those nodes. A rich literature exists
on analysing the mathematical properties of these trees [cite?], and numerous
methods exist to infer them~\citep{felsenstein2004inferring}. The situation is
quite different in recombining organisms, where the analysis of genetic data
depends on summaries ultimately derived from the
trees~\citep{tajima1983evolutionary,tavare1984line}
such as allele frequencies and site frequency
spectra~\citep{achaz2009frequency,ralph2020efficiently},
patterns of linkage disequilibrium~\citep{mcvean2002genealogical}, and principal
components~\citep{mcvean2009genealogical}. Genealogical analysis is equally
fundamental to the study of recombining organisms, but profound technical
difficulties have made the routine inference of recombinant genealogies
impossible, and therefore tree-based analysis methods have been largely
unavailable to the fields of population and statistical
genetics.

Recent breakthroughs in large-scale inference
methods~\citep{rasmussen2014genome,kelleher2019inferring,speidel2019method,
schaefer2021ancestral,wohns2021unified}
and data representation~\citep{kelleher2016efficient}
have raised the genuine prospect of genealogical analysis becoming a standard part
of the population and statistical genetics toolkit~\citep{hejase2020summary}.
Applications using these inferred ancestries as input have
begun to appear~\citep{osmond2021estimating} and many more are sure to
follow~\citep{harris2019database}. This vibrant research area, however,
has a significant difficulty, which, if not addressed, will substantially hamper
progress. We currently lack a well-defined data-model and shared terminology
to discuss recombining genealogies,
leading to basic errors in statements about what different inference methods
produce as output (see the XXX section below), as well as presenting serious
difficulties in either comparing the outputs of different methods or
(from a users perspective) using multiple inference methods in an analysis.

In this paper we [turn into proper round up paragraph later]
\begin{enumerate}
\item Discuss the classical Ancestral Recombination Graph formulation,
and show how it derives from (and is limited by) the coalescent with
recombination.
\item Suggest a definition of ARGs that is free of these limitations,
where the formulation is derived from a (normally diploid) pedigree rather than from
coalescent approximations, and where the genetic
material which is transmitted is described by annotations attached to
edges rather than nodes.
\item Suggest a classification of ARG nodes that helps us to understand
the properties of the structures inferred by different methods, and illustrate
with some examples.
% Perhaps we should also mention something about simplification and unknowable
% nodes, e.g. "show how some of the nodes are not required for useful interpretation
% of ancestry".
\end{enumerate}

\section*{Ancestral graphs and stochastic processes}
The coalescent~\citep{kingman1982coalescent,kingman1982genealogy,
hudson1983testing, tajima1983evolutionary}
provides the theoretical underpinning for much of contemporary population genetics.
Hudson extended the coalescent to include
recombination~\citep{hudson1983properties,hudson1990gene}
and the model has proved to be an especially powerful basis for
simulations~\citep{hudson2002generating,baumdicker2021efficient}.
Hudson's algorithm is concerned with simulating the process of
the coalescent with recombination as efficiently as possible, and operates by
tracking segments of ancestral material carried by ancestors as
we go backwards in time. The details of Hudson's algorithm and how the
results of the ancestral process are represented are critical to later
discussions, and so we will explain the process in some detail.
See~\cite{kelleher2016efficient} for a more detailed
description of the algorithm, and how it may be implemented efficiently.


\begin{figure}[ht]
\centering
% FIXME this is a quick nasty hack to make the figure a bit smaller and
% prevent flushing all the other figures to the end of the document.
\scalebox{0.5}{
\begin{tabular}{cc}
\begin{tikzpicture}
	\draw (-0.4, -0.2) -- (0.4, -0.2) -- (0.4, -0.3) -- (-0.4, -0.3) -- (-0.4, -0.2);
	\draw (-0.1, -0.1) -- (-0.1, -0.4);
	\node [label=below:{\small $v$}] at (-0.1, -0.2) {};
	\draw (3.6, -0.2) -- (4.4, -0.2) -- (4.4, -0.3) -- (3.6, -0.3) -- (3.6, -0.2);
	\draw (5.6, -0.2) -- (6.4, -0.2) -- (6.4, -0.3) -- (5.6, -0.3) -- (5.6, -0.2);

	\draw (4,0) -- (4, 1.2) -- (6, 1.2) -- (6,0);
	\draw (4.6, 1) -- (5.4, 1) -- (5.4, 0.9) -- (4.6, 0.9) -- (4.6, 1);
	\draw (5.1, 1.1) -- (5.1, 0.8);
	\node [label=below:{\small $w$}] at (5.1, 1) {};

	\draw (0, 0) -- (0, 1.5) -- (-1,1.5) -- (1,1.5);
	\draw (-1.4, 1.3) -- (-1.1, 1.3) -- (-1.1, 1.2) -- (-1.4, 1.2) -- (-1.4, 1.3);
	\draw (-1.1, 1.25) -- (-0.6, 1.25);
	\draw (0.6, 1.25) -- (0.9, 1.25);
	\draw (0.9, 1.3) -- (1.4, 1.3) -- (1.4, 1.2) -- (0.9, 1.2) -- (0.9, 1.3);
	\draw (1.2, 1.4) -- (1.2, 1.1);
	\node [label=below:{\small $x$}] at (1.2, 1.3) {};

	\draw (5, 1.2) -- (5, 2.4) -- (4,2.4) -- (6,2.4);
	\draw (3.6, 2.2) -- (4.1, 2.2) -- (4.1, 2.1) -- (3.6, 2.1) -- (3.6, 2.2);
	\draw (4.1, 2.15) -- (4.4, 2.15);
	\draw (5.6, 2.15) -- (6.1, 2.15);
	\draw (6.1, 2.2) -- (6.4, 2.2) -- (6.4, 2.1) -- (6.1, 2.1) -- (6.1, 2.2);

	\draw (1, 1.5) -- (1, 3.1) -- (0,3.1) -- (2,3.1);
	\draw (-0.4, 2.85) -- (0.2, 2.85);
	\draw (0.2, 2.9) -- (0.4, 2.9) -- (0.4, 2.8) -- (0.2, 2.8) -- (0.2, 2.9);
	\draw (1.6, 2.85) -- (1.9, 2.85);
	\draw (1.9, 2.9) -- (2.2, 2.9) -- (2.2, 2.8) -- (1.9, 2.8) -- (1.9, 2.9);
	\draw (2.2, 2.85) -- (2.4, 2.85);

	\draw (-1, 1.5) -- (-1, 4.5) -- (0,4.5) -- (0,3.1);
	\node [scale=0.2,label=above left:{\small A}] at (-0.5,4.5) {A};
	\draw (-0.9, 4.3) -- (-0.6, 4.3) -- (-0.6, 4.2) -- (-0.9, 4.2) -- (-0.9, 4.3);
	\draw (-0.6, 4.25) -- (-0.3, 4.25);
	\draw (-0.3, 4.3) -- (-0.1, 4.3) -- (-0.1, 4.2) -- (-0.3, 4.2) -- (-0.3, 4.3);
	\draw (-0.5, 4.4) -- (-0.5, 4.1);
	\node [label=below:{\small $y$}] at (-0.5, 4.3) {};

	\draw (4,2.4) -- (4,5.4) -- (2,5.4) -- (2,3.1);
	\node [scale=0.2,label=above left:{\small B}] at (3,5.4) {B};
	\draw (2.6, 5.2) -- (2.9, 5.2) -- (2.9, 5.1) -- (2.6, 5.1) -- (2.6, 5.2);
	\draw (2.9, 5.15) -- (3.4, 5.15);

	\draw (-0.5, 4.5) -- (-0.5, 6) -- (-1.5,6) -- (0.5,6);
	\draw (-1.9, 5.75) -- (-1.3, 5.75);
	\draw (-1.3, 5.8) -- (-1.1, 5.8) -- (-1.1, 5.7) -- (-1.3, 5.7) -- (-1.3, 5.8);
	\draw (0.1, 5.8) -- (0.4, 5.8) -- (0.4, 5.7) -- (0.1, 5.7) -- (0.1, 5.8);
	\draw (0.4, 5.75) -- (0.9, 5.75);

	\draw (0.5, 6) -- (0.5, 7.2) -- (3,7.2) -- (3,5.4);
	\node [scale=0.2,label=above:{\small C}] at (1.75,7.2) {C};
	\draw (1.35, 6.95) -- (2.15, 6.95);

	\draw (-1.5, 6) -- (-1.5, 8);
	\draw (6, 2.4) -- (6, 8);

	% Edge annotations above each event
	\node [label=left:{\small$\{[0,L)\};1$}] at (0.2,0.6) {}; 
	\node [label=left:{\small$\{[0,L)\};1$}] at (4.2,0.4) {}; 
	\node [label=right:{\small$\{[0,L)\};1$}] at (5.8,0.4) {}; 
	\node [label=left:{\small$\{[0,L)\};2$}] at (5.2,1.6) {}; 
	\node [label=left:{\small$\{[0,v)\};1$}] at (-0.8,2.3) {}; 
	\node [label=right:{\small$\{[v,L)\};1$}] at (0.8,2.1) {}; 
	\node [label=right:{\small$\{[0,w)\};2$}] at (3.8,3.9) {}; 
	\node [label=left:{\small$\{[w,L)\};2$}] at (6.2,5) {}; 
	\node [label=right:{\small$\{[x,L)\};1$}] at (-0.2,3.8) {}; 
	\node [label=right:{\small$\{[v,x)\};1$}] at (1.8,4.1) {}; 
	\node [label=left:{\small$\{[0,v), [x, L)\};1$}] at (-0.3,5.2) {}; 
	\node [label=right:{\small$\{[0,v)\};2$}] at (2.8,6.4) {};
	\node [label=left:{\small$\{[x,L)\};1$}] at (-1.3,7) {};
	\node [label=right:{\small$\{[0,v)\};1$}] at (0.3,6.4) {};

	% Dashed lines for start and end times
	\draw[dashed] (-2, 0) -- (11.1, 0);
	\node [label=left:{$t = 0$}] at (-2,0) {};
	\draw[dashed] (-2, 8) -- (11.1, 8);
	\node [label=left:{$t = T$}] at (-2,8) {};

	% Numbers of extant ancestors and links, from top to bottom
	\node[label=right:{CA \; RE}] at (7.5, 8.2) {};
	\node[label=right:{$\binom{2}{2}$ \; $(2 L - x - w) \rho$}] at (7.5, 7.6) {};
	\node[label=right:{$\binom{4}{2}$ \; $(2 L + 2 v - x - w) \rho$}] at (7.5, 6.6) {};
	\node[label=right:{$\binom{3}{2}$ \; $(2 L + v - w) \rho$}] at (7.5, 5.7) {};
	\node[label=right:{$\binom{4}{2}$ \; $(2 L + x - v) \rho$}] at (7.5, 4.95) {};
	\node[label=right:{$\binom{5}{2}$ \; $2 L \rho$}] at (7.5, 3.8) {};
	\node[label=right:{$\binom{4}{2}$ \; $2 L \rho$}] at (7.5, 2.75) {};
	\node[label=right:{$\binom{3}{2}$ \; $2 L \rho$}] at (7.5, 1.95) {};
	\node[label=right:{$\binom{2}{2}$ \; $2 L \rho$}] at (7.5, 1.35) {};
	\node[label=right:{$\binom{3}{2}$ \; $3 L \rho$}] at (7.5, 0.6) {};

	% Gray dashed lines to visually separate holding times
	\draw[color=gray, dashed] (7.5, 1.2) -- (11.1, 1.2);
	\draw[color=gray, dashed] (7.5, 1.5) -- (11.1, 1.5);
	\draw[color=gray, dashed] (7.5, 2.4) -- (11.1, 2.4);
	\draw[color=gray, dashed] (7.5, 3.1) -- (11.1, 3.1);
	\draw[color=gray, dashed] (7.5, 4.5) -- (11.1, 4.5);
	\draw[color=gray, dashed] (7.5, 5.4) -- (11.1, 5.4);
	\draw[color=gray, dashed] (7.5, 6) -- (11.1, 6);
	\draw[color=gray, dashed] (7.5, 7.2) -- (11.1, 7.2);
\end{tikzpicture}
&
\begin{tikzpicture}
	\draw (-0.4, -0.2) -- (0.4, -0.2) -- (0.4, -0.3) -- (-0.4, -0.3) -- (-0.4, -0.2);
	\draw (-0.1, -0.1) -- (-0.1, -0.4);
	\node [label=below:{\small $v$}] at (-0.1, -0.2) {};
	\draw (3.6, -0.2) -- (4.4, -0.2) -- (4.4, -0.3) -- (3.6, -0.3) -- (3.6, -0.2);
	\draw (5.6, -0.2) -- (6.4, -0.2) -- (6.4, -0.3) -- (5.6, -0.3) -- (5.6, -0.2);

	\draw (4,0) -- (4, 1.2) -- (6, 1.2) -- (6,0);
	\draw (4.6, 1) -- (5.4, 1) -- (5.4, 0.9) -- (4.6, 0.9) -- (4.6, 1);
	\draw (5.1, 1.1) -- (5.1, 0.8);
	\node [label=below:{\small $w$}] at (5.1, 1) {};

	\draw (0, 0) -- (0, 1.5) -- (-1,1.5) -- (1,1.5);
	\draw (-1.4, 1.3) -- (-1.1, 1.3) -- (-1.1, 1.2) -- (-1.4, 1.2) -- (-1.4, 1.3);
	\draw (-1.1, 1.25) -- (-0.6, 1.25);
	\draw (0.6, 1.25) -- (0.9, 1.25);
	\draw (0.9, 1.3) -- (1.4, 1.3) -- (1.4, 1.2) -- (0.9, 1.2) -- (0.9, 1.3);
	\draw (1.2, 1.4) -- (1.2, 1.1);
	\node [label=below:{\small $x$}] at (1.2, 1.3) {};

	\draw (5, 1.2) -- (5, 2.4) -- (4,2.4) -- (6,2.4);
	\draw (3.6, 2.2) -- (4.1, 2.2) -- (4.1, 2.1) -- (3.6, 2.1) -- (3.6, 2.2);
	\draw (4.1, 2.15) -- (4.4, 2.15);
	\draw (5.6, 2.15) -- (6.1, 2.15);
	\draw (6.1, 2.2) -- (6.4, 2.2) -- (6.4, 2.1) -- (6.1, 2.1) -- (6.1, 2.2);
	\draw [color=red](5.8, 2.3) -- (5.8, 2.0);
	\node [label={[red]below:{\small $z$}}] at (5.8, 2.1) {};

	\draw (1, 1.5) -- (1, 3.1) -- (0,3.1) -- (2,3.1);
	\draw (-0.4, 2.85) -- (0.2, 2.85);
	\draw (0.2, 2.9) -- (0.4, 2.9) -- (0.4, 2.8) -- (0.2, 2.8) -- (0.2, 2.9);
	\draw (1.6, 2.85) -- (1.9, 2.85);
	\draw (1.9, 2.9) -- (2.2, 2.9) -- (2.2, 2.8) -- (1.9, 2.8) -- (1.9, 2.9);
	\draw (2.2, 2.85) -- (2.4, 2.85);

	\draw (-1, 1.5) -- (-1, 4.5) -- (0,4.5) -- (0,3.1);
	\draw (-0.9, 4.3) -- (-0.6, 4.3) -- (-0.6, 4.2) -- (-0.9, 4.2) -- (-0.9, 4.3);
	\draw (-0.6, 4.25) -- (-0.3, 4.25);
	\draw (-0.3, 4.3) -- (-0.1, 4.3) -- (-0.1, 4.2) -- (-0.3, 4.2) -- (-0.3, 4.3);
	\draw (-0.5, 4.4) -- (-0.5, 4.1);
	\node [label=below:{\small $y$}] at (-0.5, 4.3) {};

	\draw (6, 2.4) -- (6, 3.8) -- (7, 3.8);
	\draw [color=red](6, 3.8) -- (5, 3.8);
	\draw (4.6, 3.55) -- (5.4, 3.55);
	\draw (6.6, 3.55) -- (7.1, 3.55);
	\draw (7.1, 3.6) -- (7.4, 3.6) -- (7.4, 3.5) -- (7.1, 3.5) -- (7.1, 3.6);

	\draw (4,2.4) -- (4,5.4) -- (2,5.4) -- (2,3.1);
	\draw (2.6, 5.2) -- (2.9, 5.2) -- (2.9, 5.1) -- (2.6, 5.1) -- (2.6, 5.2);
	\draw (2.9, 5.15) -- (3.4, 5.15);

	\draw (-0.5, 4.5) -- (-0.5, 6) -- (-1.5,6) -- (0.5,6);
	\draw (-1.9, 5.75) -- (-1.3, 5.75);
	\draw (-1.3, 5.8) -- (-1.1, 5.8) -- (-1.1, 5.7) -- (-1.3, 5.7) -- (-1.3, 5.8);
	\draw (0.1, 5.8) -- (0.4, 5.8) -- (0.4, 5.7) -- (0.1, 5.7) -- (0.1, 5.8);
	\draw (0.4, 5.75) -- (0.9, 5.75);

	\draw [color=red](5, 3.8) -- (5, 6.6) -- (4, 6.6);
	\draw (4,6.6) -- (3,6.6) -- (3, 5.4);
	\draw (3.6, 6.4) -- (3.9, 6.4) -- (3.9, 6.3) -- (3.6, 6.3) -- (3.6, 6.4);
	\draw (3.9, 6.35) -- (4.4, 6.35);

	\draw (0.5, 6) -- (0.5, 7.2) -- (4,7.2) -- (4,6.6);
	\draw (1.85, 6.95) -- (2.65, 6.95);

	\draw (-1.5, 6) -- (-1.5, 8);
	\draw [color=red](2.25, 7.2) -- (2.25, 8);
	\draw (7, 3.8) -- (7, 8);

	% Dashed lines for start and end times
	\draw[dashed] (-2, 0) -- (11, 0);
	\node [label=left:{$t = 0$}] at (-2,0) {};
	\draw[dashed] (-2, 8) -- (11, 8);
	\node [label=left:{$t = T$}] at (-2,8) {};

	% Numbers of extant ancestors and links, from top to bottom
	\node[label=right:{CA \; RE}] at (7.5, 8.2) {};
	\node[label=right:{$\binom{3}{2}$ \; $3 L \rho$}] at (7.5, 7.6) {};
	\node[label=right:{$\binom{4}{2}$ \; $4 L \rho$}] at (7.5, 6.9) {};
	\node[label=right:{$\binom{5}{2}$ \; $5 L \rho$}] at (7.5, 6.3) {};
	\node[label=right:{$\binom{4}{2}$ \; $4 L \rho$}] at (7.5, 5.7) {};
	\node[label=right:{$\binom{5}{2}$ \; $5 L \rho$}] at (7.5, 4.95) {};
	\node[label=right:{$\binom{6}{2}$ \; $6 L \rho$}] at (7.5, 4.15) {};
	\node[label=right:{$\binom{5}{2}$ \; $5 L \rho$}] at (7.5, 3.45) {};
	\node[label=right:{$\binom{4}{2}$ \; $4 L \rho$}] at (7.5, 2.75) {};
	\node[label=right:{$\binom{3}{2}$ \; $3 L \rho$}] at (7.5, 1.95) {};
	\node[label=right:{$\binom{2}{2}$ \; $2 L \rho$}] at (7.5, 1.35) {};
	\node[label=right:{$\binom{3}{2}$ \; $3 L \rho$}] at (7.5, 0.6) {};

	% Gray dashed lines to visually separate holding times
	\draw[color=gray, dashed] (7.5, 1.2) -- (11, 1.2); 
	\draw[color=gray, dashed] (7.5, 1.5) -- (11, 1.5); 
	\draw[color=gray, dashed] (7.5, 2.4) -- (11, 2.4); 
	\draw[color=gray, dashed] (7.5, 3.1) -- (11, 3.1); 
	\draw[color=gray, dashed] (7.5, 3.8) -- (11, 3.8);
	\draw[color=gray, dashed] (7.5, 4.5) -- (11, 4.5); 
	\draw[color=gray, dashed] (7.5, 5.4) -- (11, 5.4);
	\draw[color=gray, dashed] (7.5, 6) -- (11, 6); 
	\draw[color=gray, dashed] (7.5, 6.6) -- (11, 6.6);
	\draw[color=gray, dashed] (7.5, 7.2) -- (11, 7.2); 
\end{tikzpicture}
\end{tabular}
}
\caption{(A)
A realisation of the graph traversed by Hudson's algorithm started from a
sample of three continuous chromosomes of length $L$ at time $t = 0$, and
propagated until time $T$. The MRCA on the genetic interval $[v, w)$ is reached
at event B, while that on $[0, v)$ is reached at event C.
The non-ancestral segment $[v, w)$ above
A contributes to the rate of effective recombinations because it
is trapped between ancestral segments. The two columns titled CA and RE
are the respective rates of mergers and recombinations when
the recombination rate is $\rho$.
(B) A corresponding realisation of a big ARG, which augments Hudson's algorithm
by tracking nonancestral lineages. The result is a simpler state space and
dynamics, at the cost of extra nodes and edges, highlighted in red, which do
not affect the local tree at any site.}
\label{hudson_vs_bigARG}
\end{figure}

Hudson's algorithm operates by tracking the state of a set of ancestral
lineages as we go backwards in time.
% jk-note unclear here about the best choice of notation. We could have
% lists of tuples (l, r, a), or a tuple of vectors (l_j, r_j, a_j),
% of a tuple (I_j, a_j), where I is a vector of intervals. Going to
% stick with the original tuple notation for now.
%
% Each lineage consists of a set of
% equal-length vectors $\mathbf{l}$, $\mathbf{r}$ and $\mathbf{a}$
% such that for each $1 \leq j \leq \left| l \right|$,
% $[\mathbf{l}_j, \mathbf{r}_j)$ is a half-closed genomic interval and
% $\mathbf{a}_j$ is an integer
% tracking the number of samples the lineage is ancestral to over the interval.
% Assume that the intervals are sorted from left-to-right so that $\mathbf{l}_1$
% and $\mathbf{r}_{|\mathbf{r}|}$ are the left- and right-most positions
% covered by the lineage, respectively.
Each lineage consists of a list of
disjoint ancestry segments $(\ell, r, a)$, where
$[\ell, r)$ is a half-closed genomic interval and $a$ is an integer
tracking the number of samples to which the lineage is ancestral over that interval.
(We also usually track the tree node associated with each segment, but
that is not important for our purposes here so we omit it.)
If we have $n$ samples and a genome of length $m$, the process begins with $n$ lineages
of the form $\{(0, m, 1)\}$. The process then works backwards in time from
the present day as a series of random common ancestor or recombination events.
Recombination events occur at a rate determined by the amount of ancestral material and
the way in which it is distributed along a chromosome.
Let $L$ be the set of ancestors at a given time $t$. Recombination events
happen at rate $\rho \nu / (m - 1)$ where
\[
\nu = \sum_{x \in L}\left( \max_{(\ell, r, a) \in x}r
    - \min_{(\ell, r, a) \in x}\ell - 1 \right)
\]
is the number of available `links' that may be broken. Thus, the rate of
recombination is determined by the left- and right-most extent of the
ancestral material carried by each lineage. At a recombination
event we choose one of these links uniformly and break it. Given a lineage
$x = [(\ell_j, r_j, a_j)]$ and a breakpoint $k$, we have two lineages
$x_1$ and $x_2$ such that FILL IN DETAILS

When $k = |L|$ lineages are present, common ancestor events
occur at rate $\binom{k}{2}$. In a common ancestor event, two lineages
are chosen uniformly at random and their ancestry segments merged.
If we have overlapping intervals of ancestry from the two lineages,
say, $(\ell, r, a_1)$ and $(\ell, r, a_2)$, a
\emph{coalescence} occurs and ancestor represented by the current event
will be present as a node (at least) in the marginal trees covering
the interval $[\ell, r)$. The result of this coalescence is a segment
$(\ell, r, a_1 + a_2)$, and if $a_1 + a_2 < n$ it is included in the
ancestry for the new lineage. Otherwise, if $a_1 + a_2 = n$ we know that
we have found the most recent common ancestor of all samples in
the interval $[\ell, r)$ and so we do not need to simulate its history any further.
Nonoverlapping intervals of ancestry from the two lineages are included
in the resulting lineage without changes. Eventually, as the process continues,
we find resultant lineages in which all segments have fully coalescenced,
and so the number of extant lineages gradually dwindles down to zero.

% NOTE: it would probably be helpful to have a drawing of the ARG process
% in-progress here to help us talk about it. What is the full state
% that is remembered as we go through the process? It does help to think
% about the process as choosing edges to merge, not nodes.
The Ancestral Recombination Graph (ARG) was later introduced by
Griffiths~\citep{griffiths1991two,ethier1990two,griffiths1996ancestral,
griffiths1997ancestral}, and is a
closely related and complementary treatment of the same process. Where
Hudson's algorithm is focused on the efficient \emph{simulation} of the
process, the original ARG literature is focused on mathematical
results about the stochastic process. Griffiths and colleagues used the word
``ARG'' to refer to both a specific branching-coalescing stochastic process and
the graph structure derived from this process. For clarity, we will refer to the
process as the Griffiths process, or the coalescent with recombination (CwR),
and following XX-Who?-XX, we refer to the the structure as the ``big ARG'', as
opposed to the ``little ARG'' traversed by Hudson's algorithm
(\citet{wiuf1999recombination} refer to these structures as ARG and HUD respectively).

In the Griffiths formulation, each edge in the graph corresponds to an extant
lineage and nodes are events in the process (the initial $n$ leaf nodes are
``sampling'' events). As in Hudson's
algorithm, common ancestor events occur at rate $\binom{k}{2}$ when there
are $k$ lineages present. We choose two lineages (edges) uniformly, and merge them
into a common ancestor lineage. Recombination events are different
to Hudson's algorithm, however. Rather than occuring at a rate which depends on
the specific distribution of ancestral material among lineages, the
rate of recombination is now simply $k \rho (m - 1)$. At a recombination event
we choose a lineage (edge) uniformly, and a
breakpoint $0 < x < L$ uniformly on its genome. We terminate the edge at a
node, record the breakpoint and start two new edges from this node. The process
then continues until there is only one lineage left (the Grand Most Recent
Common Ancestor, GMRCA), which is guaranteed to
happen in finite time because of the linear vs quadratic rates of branching
and coalescing. The graph structure and breakpoints associated with
recombination nodes provides sufficient information to later recover the marginal
trees (see the next section for more details and discussion on this point).

The state-space of the Griffiths process is much simpler than Hudson's algorithm,
which greatly facilitates mathematical reasoning. This simplicity comes at a
substantial cost, however, if we wish to use it as a practical means of
simulating recombinant ancestry. The big ARG is vast, and any realisation
for even moderate levels of recombination is far too large to be of practical
use. The number of events in the big ARG, all the way back to the GMRCA
is $O(e^\rho)$~\citep{griffiths1997ancestral}, whereas the number
of events required to simulate the little ARG is
$O(\rho^2)$~\citep{hein2004gene,baumdicker2021efficient}.
This disparity in the number of events in the two formulations is
because the majority of the events that occur in the big ARG do
not affect the genetic ancestry of the sample in any way. Recombination
events that occur outside of ancestral material do not have any bearing
on the ancestry of the sample, and so the structure is hugely redundant.
As~\cite{wiuf1999recombination} note,
``an `ancestral' sequence in the birth and death process
need not have any genetic material in common with a
sequence descended from it.''

% Full quote:
% This process simplifies mathematics on the account that the notion of an
% ancestor will have a less restrictive meaning than usual:
% An ``ancestral'' sequence in the birth and death process
% need not have any genetic material in common with a
% sequence descended from it.

[Review of other work done on the ARG stochastic process here.
Discuss \citet{wiuf1999ancestry}. Wiuf and Hein's classical pair of papers
clarified the relationship between Hudson's algorithm and the ARG.
Explain that ARG simulation is inherently less efficient than Hudson's
algorithm because we must track all lineages, even those that correspond
to sections that have coalesced, or we won't have a complete ARG.
This might be tricky to communicated without a figure, but is an
esoteric point perhaps not worth spending a figure on.]

Similar graph encodings have also been introduced to model other mechanisms
which change the local ancestral tree along the genome, such as gene
conversion~\citep{wiuf2000coalescent} and
horizontal gene transfer~\citep{baumdicker2014infinitely}.
[Mention the
SMC~\citep{mcvean2005approximating,marjoram2006fast}
and ClonalFrame~\citep{didelot2007inference} approximations somewhere.]

The idea of using branching-coalescing stochastic processes
to model genetic ancestral trees has also found application in natural selection.
The Ancestral Selection Graph (ASG)~\citep{krone1997ancestral,neuhauser1997genealogy}
uses dynamics identical to the ``big'' ARG to simulate an ensemble of correlated
potential ancestral trees. Weak genic selection is incorporated by sampling a
true ancestry from the ensemble in a non-uniform way.
There is no ASG analogue of the more computationally tractable ``little'' ARG,
though some gains in tractability can be made by considering typed
lineages~\citep{etheridge2009coalescent} or by leveraging perfect simulation
techniques when recurrent mutation is present\citep{fearnhead2001perfect}.
Extensions of the ASG have been developed to frequency-dependent
selection~\citep{neuhauser1999ancestral, gonzalezcasanova2018duality},
unlinked chromosomes~\citep{fearnhead2003ancestral}, recombining
loci whereupon branching is due to both selection and
recombination~\citep{donnelly1999genealogical}, and high fecundity
reproduction~\citep{gonzalezcasanova2018duality, koskela2019robust}.

\section*{The ARG as a data structure}
Early work on ARG inference focused on the problem of
of inferring parameters of the
stochastic process, where the ancestry is regarded as a
latent parameter to be averaged out
\citep[e.g.][]{griffiths1996ancestral,kuhner2000maximum, nielsen2000estimation,
fearnhead2001estimating}. These methods met with limited success
due to the overwhelmingly large and
horribly structured [Jere: what's the right way to say this?]
state space of ARGs. The focus subsequently shifted to
the more tractable---but still
NP-hard~\citep{wang2001perfect}---problem of computing
the minimum number of recombinations required
to explain an input dataset [CITATIONS], and inferring the corresponding
ARG realisations~\citep{song2003parsimonious,song2005efficient,lyngso2005minimum}.
The distinction between the ARG as a stochastic process
and the ARG as a data structure became less clear at this point,
with \citet{minichiello2006mapping} explicitly arguing for
the data structure interpretation.

The Griffiths ARG encoding is an elegant and mathematically
economical description of the coalescent with recombination on a single
chromosome, but it has significant drawbacks as the basis for a general purpose
storage and interchange format.
The concrete details of how an ARG should be stored and processed
are not discussed in the literature, % weak, fix.
but the following is a reasonable approach that mirrors the implementations
in methods such as [x, y z].
A Griffiths ARG is composed of a set of $N$ nodes, where each node is an
integer $0 \leq u < N$, and edges $(u, v)$ define the relationships between
those nodes (Fig.~\ref{fig-arg-data-structure}A).
Each node corresponds to an \emph{event}, and is either a common ancestor
event (in which case it has two children and one parent)
or a recombination event (when it has one child and two parents).
Each recombination event is associated with a breakpoint $0 < x < L$,
which we might encode as a mapping $f: N \rightarrow \{0, ..., L - 1\}$
such that $f(u)$ is the recombination breakpoint if $u$ is a recombination
node and $f(u) = \infty$ otherwise. This encoding captures the information
of a realisation of the ARG stochastic process, but it is important to
note that it does not uniquely describe the underlying ancestral history
without stipulating some additional ordering requirements.


\begin{figure}
\centering
\begin{tabular}{cc}
\begin{tikzpicture}[x=5mm, y=5mm, node distance=2mm and 20mm]
\tikzset{greynode/.style={circle,fill,inner sep=1},
nodelabel/.style={font=\footnotesize}}

\node (s0) [greynode] at (0, 0) {};
\node (s1) [greynode] at (3, 0) {};
\node (s2) [greynode] at (6, 0) {};
\node (s3) [greynode] at (3, 1) {};
\node (s4) [greynode] at (1, 2) {};
\node (s5) [greynode] at (5, 3) {};
\node (s6) [greynode] at (3, 4) {};

\node [nodelabel,anchor=north west] at ($(s3) + (0,0)$) {$x$};
\foreach \u/\lab in {s0/0, s1/1, s2/2} \node[nodelabel,anchor=north] at (\u) {\lab};
\foreach \u/\lab in {s4/4} \node[nodelabel,anchor=south west] at (\u) {\lab};
\foreach \u/\lab in {s5/5} \node[nodelabel,anchor=south east] at (\u) {\lab};
\foreach \u/\lab in {s3/3, s6/6} \node[nodelabel,anchor=south] at (\u) {\lab};

%% Edges
\draw (s1) -- (s3);
\draw (s0) |- (s4);
\draw (s4) -- (2,2) |- (s3);
\draw (s4) |- (s6);
\draw (s3) -- (4,1) |- (s5);
\draw (s2) |- (s5);
\draw (s5) |- (s6);

\node [nodelabel,anchor=north west] at ($(-6.5,5)$) {
\begin{tabular}{c|c}
\multicolumn{2}{c}{Breakpoint}\\
\hline
0 & $\infty$ \\
1 & $\infty$ \\
2 & $\infty$ \\
3 & $x$ \\
4 & $\infty$ \\
5 & $\infty$ \\
6 & $\infty$ \\
\end{tabular}};

\node [nodelabel,anchor=north west] at ($(-2.5,5)$) {
\begin{tabular}{l}
Edges\\
\hline
$(0, 4)$ \\
$(1, 3)$ \\
$(2, 5)$ \\
$(3, 4)$ \\
$(3, 5)$ \\
$(4, 6)$ \\
$(5, 6)$ \\
\end{tabular}};

\end{tikzpicture}
&
\begin{tikzpicture}[x=5mm,y=5mm,node distance=2mm and 20mm]
\tikzset{greynode/.style={circle,fill,inner sep=1},
nodelabel/.style={font=\footnotesize}}

\node (s0) [greynode] at (0, 0) {};
\node (s1) [greynode] at (3, 0) {};
\node (s2) [greynode] at (6, 0) {};
\node (s3) [greynode] at (2, 1) {};
\node (s4) [greynode] at (4, 1) {};
\node (s5) [greynode] at (1, 2) {};
\node (s6) [greynode] at (5, 3) {};
\node (s7) [greynode] at (3, 4) {};

\foreach \u/\lab in {s0/0, s1/1, s2/2} \node[nodelabel,anchor=north] at (\u) {\lab};
\foreach \u/\lab in {s3/3} \node[nodelabel,anchor=east] at (\u) {\lab};
\foreach \u/\lab in {s4/4} \node[nodelabel,anchor=west] at (\u) {\lab};
\foreach \u/\lab in {s5/5} \node[nodelabel,anchor=south west] at (\u) {\lab};
\foreach \u/\lab in {s6/6} \node[nodelabel,anchor=south east] at (\u) {\lab};
\foreach \u/\lab in {s7/7} \node[nodelabel,anchor=south] at (\u) {\lab};

%% Edges
\draw (s1) |- (s3);
\draw (s1) |- (s4) |- (s6);
\draw (s3) |- (s5);
\draw (s0) |- (s5);
\draw (s2) |- (s6);
\draw (s5) |- (s7);
\draw (s6) |- (s7);

\node [nodelabel,anchor=north west] at ($(-5,5)$) {
\begin{tabular}{ll}
Edges\\
\hline
$(0, 5)$ & $(0, L]$ \\
$(1, 3)$ & $(0, x]$ \\
$(1, 4)$ & $(x, L]$ \\
$(2, 6)$ & $(0, L]$ \\
$(3, 5)$ & $(0, L]$ \\
$(4, 6)$ & $(0, L]$ \\
$(5, 7)$ & $(0, L]$ \\
$(6, 7)$ & $(0, L]$ \\
\end{tabular}};

\end{tikzpicture}
\\
(A) & (B) \\
\end{tabular}
\caption{\label{fig-arg-data-structure}
Encoding an ARG. (A) The classical approach described by Griffiths
equates graph nodes with events in the stochastic process,
and associates recombination breakpoints with nodes. This encoding
is limited in the ancestral patterns that can be described and ambiguous.
(B) Equating graph nodes with \emph{genomes} and attaching the
interval of genome inherited by the child node with edges removes
this ambiguity and can describe any pattern of genetic inheritance.
The most important change between the two encodings is to represent
a recombination event (node 3 in A) by two parent genomes
(nodes 3 and 4 in B) and explicitly storing the interval
that the child inherits from each parent along the two corresponding
edges. Thus, child $1$ in inherits $(0, x]$ from $3$
and $(x, L)$ from $4$
(for recombination breakpoint $x$ and a sequence of length $L$).
\textcolor{red}{This is very much a draft; let's see how it works with
 the text and other figures and tidy it up in a later revision}
}
\end{figure}

The Griffiths ARG encoding is ambiguous because it does not explicitly
define which of the parent lineages resulting from a recombination
event carries ancestral material to the left or right of the
breakpoint. The ambiguity is resolved by adopting a simple rule when
traversing the graph in order to generate the marginal trees for a
given position $z$: at a recombination node $u$, we follow the
first edge in which $u$ is a child if $f(u) \leq z$, and the
second edge otherwise. This ordering requirement, which straightforward
% Saying "awkward" too many times here, rephrase.
to describe can be awkward in practice. For example,
simulating an ARG in this representation is considerably
complicated by the fact that the
first event to occur may hit the right-hand lineage rather
than the left.
Such awkwardnesses can be worked around, of course,
but in practice methods such has
\texttt{beagle}~\citep{lyngso2005minimum} and
\texttt{KwARG}~\citep{ignatieva2021kwarg}
resolve this problem by
associating a label ``P'' (prefix) or ``S'' (suffix) with the
outbound edges of a recombination event.

% it's not reasonable to assume that one type of event happens
% at a time any more.
The Griffiths ARG encoding is also limited in the types of ancestral
history that can be described. This ARG encoding is derived from the coalescent
with recombination, which explicitly assumes that only one type
of event can occur (i.e., common ancestry or recombination) at a
time. This model is derived as an approximation to a Wright-Fisher
model, assuming that the sample size $n$ is much less than the
population size $N$ and [some assumptions about genome length]
\textcolor{red}{what is this Jere?}. While these approximations are
reasonable
to make when studying the Kreitman \emph{Drosphila Melanogaster}
dataset~\citep{kreitman1983nucleotide} ($n=11$, $N\approx 10^6$,
at 43 variant sites over x Kb \textcolor{red}{details and citation
for Ne estimate}) that is classically used for benchmarking
ARG inference methods [cites],
they are highly questionable in modern datasets. % absurd really
For example, there are now many
human datasets consisting of hundreds of thousands of
genomes~\citep{bycroft2018genome,karczewski2020mutational,tanjo2021practical},
and thus our sample size is often much \emph{larger} than $N_e$
(often assumed to be $10^4$ in humans).
% TODO make this better. Ask Gregor for some refs?
% Basically, Ag datasets make the assumption of isolated
% rare recombinations absurd.
Agricultural datasets such as the 1000 bull genomes~\citep{hayes20191000}
combine genome sequence data with detailed pedigrees, with
sample data from multiple generations.
Complete chromosome-level assemblies are now possible
in humans~\citep{miga2020telomere},
and projects are under way to obtain high-quality assemblies
for all eukaryotic species in Britain and Ireland~\citep{darwin2022sequence}
and ultimately worldwide~\citep{lewin2022earth}.
While the coalescent model can be suprisingly robust to such
basic violations to the underlying assumptions~\citep{
wakeley2012gene,bhaskar2014distortion,nelson2020accounting},
it is not acceptable that our ability to \emph{represent}
ancestral relationships should be limited by these assumptions.
In a Wright-Fisher model, coalescence and recombination can
occur at the same time in the same genomes, and we can be
certain that this is also true in the incredibly rich
datasets that are available today.

Another limitation of the Griffiths ARG encoding illustated in
Fig.~\ref{fig-arg-data-structure}A is the inability to represent
multiple recombinations along a chromosome, gene conversion,
or transmission of multiple chromosomes.
[Sentence saying ``gene conversion is important, actually, cite, cite,
so we should be hoping to infer it some day''. Presumably people
already are in bacterial contexts?]
To allow us to encode data from these important processes we
must either devise workarounds to the event based encoding
(i.e., model gene conversion as two recombination events) or
generalise the model to more appropriately reflect the realities
of modern datasets.

Fortunately, it is straightforward to generalise the classical Griffiths
encoding to both simplify implementations and to encompass any
possible pattern of genetic inheritance.
We require only two changes. Firstly, we let nodes in the
graph model \emph{genomes} rather than \emph{events}. As we
see in the next section, this allows us to model complex
patterns of inheritance without classifying different types of node.
The second change we must make is to encode
intervals of ancestry inheritance \emph{explicitly} on graph edges,
rather than \emph{implicitly} as breakpoints associated with
recombination events and edge ordering rules.
That is, given two genomes $p$
and $c$ where $p$ is the parent genome and $c$ is the child
(although many generations may have elapsed between the two),
we associate a set $I$ of intervals of genome which $c$ has
inherited from $p$.
These simple changes required to translate from the
classical Griffiths approach to the proposed encoding
are shown in Fig.\ref{fig-arg-data-structure}.

\textcolor{red}{
This falls a bit flat here,  but it's not clear how we're dividing
the responsibility for explaining the model between the
different sections.
Basically, we can't explain everything at
the end of this section, but we want to give the reader the
basic idea (which is genuinely simple). Can see how things are
shaping up after we've got a draft of the rest of the
sections, I guess.}

\section*{Anchoring the ARG to the pedigree}

The deep connection between the ARG and the pedigree is of course
well known
\citep[e.g.][]{wakeley2012genetics,gusfield2014recombinatorics,
speed2015naturereviewsgenetics}
and recent discussions of the ARG have illustrated the
relationship~\citep{mathieson2020ancestry,brandt2021evaluation}, % more??
showing how the coalescence and recombination events in an ARG
correspond to particular genomes in the pedigree.
As discussed in the previous section, the definition of the ARG
as a \emph{data structure} in terms of these two events is problematic,
fundamentally limiting the expressivity of the structure.
Following \citep{mathieson2020ancestry} we instead define the
ARG data structure \emph{in terms of} an underlying pedigree, so that
any form of inheritance structure can be modelled.
% Bit of duplication here, but good to make the point about being
% motivated by real existing datasets not some academic desire to
% model complexity that isn't there.
This, coupled with
the explicit association of genome coordinates with edges, allows
us to represent even the bewilderingly complex patterns of relatedness
present in modern datasets.

\begin{figure}
    \includegraphics[width=\textwidth]{illustrations/pedigree_figure}
\caption{\label{fig-pedigree-and-arg}
The (unannotated) ARG is closely related to the pedigree
graph, where each ``individual'' node is replaced by two ``genome''
nodes, and edges between parents and children are only included if there is
transfer of ancestral material. We usually only include nodes in an ARG
that affect our sample, so that, for example, individuals that are ancestral
to only one sampled genome are not included.}
\end{figure}

Fig~\ref{fig-pedigree-and-arg} illustrates the basic elements of the model.
The pedigree is composed of a set of individuals who each carry
two \emph{genomes} (we assume a diploidy here for concreteness, but there
is no inherent limitation on ploidy in the model).
Each genome is inherited from one of the individual's parents, and may
be the recombined product of that parent's two genomes.
For example, individual $I_1$ has two genomes $A$ and $B$,
inherited from parents $I_3$ and $I_4$. Genome $A$ is the product of
recombining $I_3$'s two genomes $E$ and $F$ at position FIXME,
whereas $B$ was inheritied directly from $I_4$'s genome $G$ without
recombination.

[Here are the basic components of the model]

\begin{enumerate}
\item A node corresponds to one of a diploid individual's two genomes.
This is linked explicitly to the pedigree, and is fully general.
Nodes \emph{may} be labelled with certain flags describing their properties,
but it's not necessary.
\item An edge between two nodes defines a genetic inheritance relationship
between two nodes. Edges are annotated with information about the
passage of ancestral materal. There are different forms these annotations
can take. For example, we can follow the approach taken in the Griffiths
ARG and just annotate recombinant edges with the interval $[0, x)$ or $[x, L)$,
depending on side of the breakpoint the edge is on. In the most
general case, we annotate each edge with the full set of disjoint
intervals of ancestral material that flows along that edge.
\citep{mcgill2013graphml} also proposed full ancestral material being
associated with each edge.
\end{enumerate}

\begin{figure}
\vspace{5em}
% NB: not clear if this figure is better off on its own or should be
% merged with the pedigree one.
\caption{\label{fig-arg-annotations}
The specific path through the ARG for a given genome position (and therefore
the local genealogical tree) cannot be determined without annotations
to the graph. (A) The classical Griffiths approach annotates recombination
nodes with the corresponding breakpoint. (B) We can equivalently
annotate the \emph{edges} with the genomic intervals carrying ancestral
material. Edge annotations are somewhat more general, and have
significant computational advantages.}
\end{figure}

\begin{figure}
\centering
\vspace{5em}
\includegraphics[width=\linewidth]{illustrations/ARG_recomb_node_deletion}
\caption{\label{fig-recombination-nodes}
Recombination nodes are optional in an edge-annotated ARG. (a) A simulated
ARG including all recombination nodes (red). (b) The same ARG having removed both
recombination nodes and nodes of common ancestors in which no genetic
lineages coalesce (cyan). (c) The sequence of trees corresponding to (b): if we were
to plot out the trees corresponding to (a) we would have more trees, but the topologies
and MRCA nodes at each genomic location would be identical. For clarity, nodes are
plotted by ranked time rather than true time on the y-axis.
% HYW: note that we also truncate nodes for portions in which they are unary,
% so that nodes which are coalescent nodes over only some of their length
% (blue-green) become coalescent nodes over their entire length (green). This
% can, however, throw away some useful information, for example node 4 has
% only a single parent edge in (a), but 2 parent edges (one of which appears
% to bypass node 11) in (b). In fact, this edge should go through node 11, but
% there may be no way to detect this from real data.
}
\end{figure}

\section*{Relationship with other types of phylogenetic networks}

The term \emph{phylogenetic network} has been broadly accepted to describe the most general
type of genealogical graph, defined by \citet{huson2010phylogenetic} as ``any graph used to
represent evolutionary relationships (either abstractly or explicitly) between a set of taxa
that labels some of its nodes'' (although more narrow and context-dependent definitions can also
be found in the literature). Explicit rooted phylogenetic networks are rooted DAGs,
with leaves labelled by the taxa (species, groups, individuals or sequences), and nodes classed
as either reticulation nodes (with in-degree $\geq 2$) or tree nodes.

Some sub-classes of explicit rooted phylogenetic networks are defined based on the evolutionary event that the
reticulation nodes capture \citep{huson2010phylogenetic}. In \emph{reassortment} networks, used to
model the evolution of viruses, reticulation nodes correspond to exchange of
(non-recombining) genomic segments between viral particles inside a co-infected host.
In \emph{hybridisation} networks, reticulation nodes correspond to genetic material from two
different species combining to create a hybrid. In \emph{recombination} networks, the reticulation nodes
correspond to recombination events (with leaves labelled by sequences and edges labelled by mutations).
The ARG is a subtype of a recombination network under this definition (restricting to one crossover
recombination per reticulation node).
% AI: Not sure about this - do ARGs also encompass multiple crossover recombinations and gene
% conversion (seems implied above)?

Sub-classes of explicit rooted phylogenetic networks can also be defined by restrictions on their topology.
In \emph{binary networks}, all internal nodes must have either in-degree two and out-degree one or in-degree
one and out-degree two (with the root having out-degree two and the leaves in-degree 1) \citep{steel2016phylogeny}.
In \emph{tree-child networks}, every internal node must have at least one child that is a tree node;
\emph{tree-sibling networks} are constrained by every reticulation node having at least one sibling that is a
tree node \citep{cardona2008extended}. Further, sub-types can be defined by restrictions on
the topology of subgraphs that contain the reticulation loops (cycles containing a reticulation node).
A reticulation loop that does not share any node with another reticulation loop is termed a gall
\citep[][p.\ 237]{gusfield2014recombinatorics}; a reticulation network containing only galls is
called a \emph{galled tree}. Reticulation loops that are joined together in a reticulation network
by at least one shared node form a blob; a \emph{level-$k$ network} is one where the maximal number
of reticulation loops inside a blob is $k$ \citep{choy2005computing}. Galled trees are level-1 networks,
and the tractability afforded by their relatively simple structure results in a number of attractive
combinatorial properties \citep{wang2001perfect, gusfield2004optimal}. We consider the general case of
an ARG, without applying any of these restrictions.
% AI: have not mentioned any implicit or un-rooted networks (split, median, haplotype, reticulograms, etc).
% Also: are we not defining ARGs as "binary networks"? Might be good to specify this here.

\section*{ARG inference methods}
Using the terminology developed here to classify ARGs, we now review methods developed
to explicitly \emph{infer} ARGs from sequencing data.

\subsection*{Parsimony and heuristics}
The problem of reconstructing ARGs for samples of recombining sequences has been of significant
 interest essentially since the ARG was first defined. Early methods focussed on finding the most
 \emph{parsimonious} ARGs, i.e.\ those minimising the number of posited recombination events in
 the history of the sample \citep{hein1990reconstructing}. Two main approaches to explicitly reconstructing
 parsimonious ARGs then emerged: building the ARG either \emph{backwards-in-time} or \emph{along-the-genome}.
 The former approach, introduced by \citet{lyngso2005minimum} and implemented in the program
 \texttt{Beagle}, starts with the input data matrix and reduces it through row and column operations
 corresponding to coalescence, mutation and recombination events, until the empty matrix is reached;
 the corresponding sequence of events can then be used to construct an ARG from the bottom up. The
 latter approach, introduced by \citet{song2003parsimonious} and first implemented in the program
 \texttt{RecMinPath} \citep{song2005constructing}, starts with an initial local tree at some starting
 position, and refines the tree moving left and right along the genome, changing the topology of the
 tree when necessary through \emph{subtree prune and regraft} (SPR) operations (corresponding to
 recombination events).

Reconstructing a most parsimonious ARG for a given data set is NP-hard \citep{wang2001perfect},
and in order to allow for larger input datasets, subsequent parsimony-based methods have resorted
to various relaxations and heuristics. Those utilising variants of the backwards-in-time approach
include the programs \texttt{SHRUB} \citep{song2005efficient}, \texttt{GAMARG} \citep{thao2019hybrid},
and \texttt{KwARG} \citep{ignatieva2021kwarg}, and the method described by \citet{wu2008association}.
Tools constructing genealogies along-the-genome include \texttt{RecPars} \citep{hein1993heuristic},
\texttt{RENT} \citep{wu2011new} and its sequel \texttt{RENT+} \citep{mirzaei2017rent}. Other approaches
include \texttt{TARGet} \citep{camara2016inference}, which implements a method based on topological
data analysis. The scalability of these methods varies substantially based on the heuristics in use
and the underlying data structure, with the most efficient tools limited to analysing hundreds of
sequences.

A number of heuristic methods have also been developed which do not (explicitly) focus on reconstructing
the most parsimonious ARGs, but rather aim for computational efficiency while seeking to achieve good
accuracy of the inferred genealogies. Such methods include \texttt{Margarita} \citep{minichiello2006mapping}
and the approach of \citet{parida2008estimating}; the more recently developed \texttt{Relate}
\citep{speidel2019method} and \texttt{tsinfer} \citep{kelleher2019inferring} use a combination of both
backwards-in-time and along-the-genome approaches, and can be practically used on megabase scale data
and tens to hundreds of thousands of samples under human-like parameters.
Another class of methods has recently emerged that use a \emph{threading} approach, constructing ARGs
by adding sequences to the graph one-by-one. Originally introduced by \citet{rasmussen2014genome} as a
way of generating MCMC proposals for ARGs, a similar idea was leveraged in \texttt{ARGneedle}
\citep{zhang2021biobank} to reconstruct ARGs for biobank-scale data.
% AI: just to note, these papers do not all agree in their definition of an ARG.
% I guess this is one of the points of the present paper, but should we mention this fact?
% Should we also mention that most of these infer just the topology, but some also the times?

\subsection*{Model-based methods}
An alternative approach is to treat the ancestry as a latent parameter to be averaged out
by Monte Carlo methods, based either on importance sampling
\citep{griffiths1996ancestral, fearnhead2001estimating, jenkins2011inference}
or MCMC \citep{kuhner2000maximum, nielsen2000estimation, wang2008bayesian, fallon2013acg}.
These methods invariably operated on a representation of the ``little ARG'', typically
generated until the grand MRCA. They are extremely computationally expensive,
and applicable to at most hundreds of samples consisting of tens of kilobases with
human-like parameters.

Due to the computational expense of sampling ``little ARGs", state-of-the-art
Monte Carlo methods typically rely on cheaper, approximate models.
The most prominent examples are \texttt{ARGWeaver} \citep{rasmussen2014genome}
and \texttt{Arbores} \citep{heine2018bridging}. The former also utilises a time
discretisation approximation, but scales to dozens of mammal-like genomes.
The \texttt{ClonalOrigin} method \citep{didelot2010inference,
medina2020speeding} uses the \texttt{ClonalFrame}
model and data structure, though it is not as scalable as \texttt{ARGWeaver}.

A very recent MCMC method called \texttt{ARGInfer} has resulted in the first
improvement in the scalability of Monte Carlo methods for the exact ARG model
by making use of the tree sequence representation of marginal trees, suitably enriched
to facilitate the computations needed for MCMC sampling \citep{mahmoudi2021inference}.
While not competitive with the scalability of \texttt{ARGWeaver}, \texttt{ARGInfer} extends
the feasible range of sequence lengths by at least an order of magnitude when
compared with methods which sample realisations of the exact ``little ARG''.


\begin{figure}
\vspace{5em}
\caption{\label{fig-inferred-args}
ARGs inferred by different methods from a small dataset. Notes about these
ARGs.
}
\end{figure}

\section*{Discussion}

Discussion points (may or may not be used, certainly would be heavily revised)

\begin{itemize}
\item Terminology based around an inferred ancestry being a ``true''
ARG is impoverished and misleading. The only reasonable interpretation
of a ARG being true or not is whether it's a sample from the coalescent.
Most inference methods (and all that scale well) do not. In any case,
the coalescent is just one model, and a highly idealised one. It is
exceedingly unlikely that the actual ARG describing the ancestry
of any biological population is ``true'' ARG in this sense. The terminology is
impoverished because it reduces the possibilities available
to something either being an ARG or not, whereas there are many different
interesting properties of these structures that we should be able to
discuss and compare.
\item tskit can represent any ARG.
\item Interchange is a real problem, and if we're going to realise the
potential for ARGs in genomics we must solve it. Efforts to standardise
phylogenetic networks haven't done very well (~\citep{cardona2008extended}
has 89 citations). The only real effort to standardise an ARG format
based on extending GraphML~\citep{mcgill2013graphml} has 11 citations.
GraphML~\citep{mcgill2013graphml} has some of the same key ideas
as tskit though, in particular allowing the annotation of ``live sites''
to an edge as a set of disjoint intervals that hold ancestral material.

\item Comparison metrics are a problem. All evaluations has essentially
looked at either some form of pairwise comparison of trees along the genome
using tree metrics, or looked at the distributions of TMRCAs. No
one has succeeded in performing any comparisons of ARGs beyond
regarding them as a sequence of independent trees. If we genuinely believe
that ARGs are more than this, then we need to devise some metrics that
consider more than the local tree structure.

\item We should discuss other types of ancestry network also.
The crucial distiction between an ARG and a phylogenetic network (I think?) is
the presence of position information specifying the location of
recombination events (and by extension, the complete passage
of ancestral material the graph). Without position information
we know that a particular node was an ancestor somewhere along the
sequence, but not exactly where.

\end{itemize}

\bibliographystyle{plainnat}
\bibliography{paper}

\end{document}
